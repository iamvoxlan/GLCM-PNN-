{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This code used to extract GLCM feature. Written by Muhammad Naufal, you can use it for educational purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below used to import all library needed to do feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below used to define the datasets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir= 'Crop ROI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below used to create empty list for saving some variables such as images that contain an array, labels for image class, and the path of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]\n",
    "img_paths=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below used to define the standard of image which is 64x64 pixel after resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 64\n",
    "height = 64\n",
    "dim = (width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all image and save the label and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir1 in os.listdir(img_dir):\n",
    "    subdir2 = img_dir+'/'+subdir1\n",
    "    for file in os.listdir(subdir2):\n",
    "        file_path = subdir2+'/'+file\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, dim)\n",
    "        images.append(img)\n",
    "        labels.append(subdir1)\n",
    "        img_paths.append(file_path)\n",
    "        if cv2.waitKey(0) & 0xff == 27: \n",
    "            cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create empty list for collection of features of many combination on whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilarity=[]\n",
    "homogeneity=[]\n",
    "contrast=[]\n",
    "ASM=[]\n",
    "energy=[]\n",
    "correlation=[]\n",
    "entropy=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below used to extract the GLCM feature, the feature that being extracted are the combination of distance 1-5 & angles 0 - 135. It took some times, so you need to be patient to wait :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for img in images:\n",
    "#     code below used to find cooccurence matrix for 20 combination of angles and distances\n",
    "    matrix_cooc = greycomatrix(img, distances=[1, 2, 3, 4, 5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256,\n",
    "                        symmetric=True, normed=False)\n",
    "    dissimilarity.append(greycoprops(matrix_cooc, 'dissimilarity'))\n",
    "    homogeneity.append(greycoprops(matrix_cooc, 'homogeneity'))\n",
    "    contrast.append(greycoprops(matrix_cooc, 'contrast'))\n",
    "    ASM.append(greycoprops(matrix_cooc, 'ASM'))\n",
    "    energy.append(greycoprops(matrix_cooc, 'energy'))\n",
    "    correlation.append(greycoprops(matrix_cooc, 'correlation'))\n",
    "    img_entropy = np.zeros((5, 4))\n",
    "    for distance in range (0, 5):\n",
    "        for angle in range(0, 4):\n",
    "            img_entropy[distance][angle] = shannon_entropy(matrix_cooc[distance][angle])\n",
    "    entropy = np.append(entropy, img_entropy)\n",
    "    counter += 1\n",
    "reshaped_entropy = np.reshape(entropy,(len(images), 5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define a function to export feature to csv, so after we run the code, we can save it and we don't have to re-run the code which took a long time to extract the feature. We can read the extracted feature after exported to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_csv(distance, angle, dissimilarity, homogeneity, contrast, ASM, energy, correlation, entropy):\n",
    "    datasets = {'dissimilarity': dissimilarity,\n",
    "            'homogeneity': homogeneity,\n",
    "            'contrast': contrast,\n",
    "            'ASM': ASM,\n",
    "            'energy': energy,\n",
    "            'correlation': correlation,\n",
    "            'entropy': entropy,\n",
    "            'labels': labels,\n",
    "            'img_paths': img_paths\n",
    "           }\n",
    "    file_name = 'glcm_'+str(distance)+'_'+str(angle)+'.csv'\n",
    "    df = pd.DataFrame(datasets, columns = ['dissimilarity', 'homogeneity', 'contrast', 'ASM', 'energy', 'correlation', 'entropy', 'labels', 'img_paths'])\n",
    "    df.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I called the csv export function for every combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance in range (0, 5):\n",
    "    for angle in range(0, 4):\n",
    "        single_dissimilarity=[]\n",
    "        single_homogeneity=[]\n",
    "        single_contrast=[]\n",
    "        single_ASM=[]\n",
    "        single_energy=[]\n",
    "        single_correlation=[]\n",
    "        single_entropy=[]\n",
    "        for feature in range (0, len(dissimilarity)):\n",
    "            single_dissimilarity.append(dissimilarity[feature][distance][angle])\n",
    "            single_homogeneity.append(homogeneity[feature][distance][angle])\n",
    "            single_contrast.append(contrast[feature][distance][angle])\n",
    "            single_ASM.append(ASM[feature][distance][angle])\n",
    "            single_energy.append(energy[feature][distance][angle])\n",
    "            single_correlation.append(correlation[feature][distance][angle])\n",
    "            single_entropy.append(reshaped_entropy[feature][distance][angle])\n",
    "            \n",
    "        single_dissimilarity= np.array(single_dissimilarity).flatten().tolist()\n",
    "        single_homogeneity= np.array(single_homogeneity).flatten().tolist()\n",
    "        single_contrast= np.array(single_contrast).flatten().tolist()\n",
    "        single_ASM= np.array(single_ASM).flatten().tolist()\n",
    "        single_energy= np.array(single_energy).flatten().tolist()\n",
    "        single_correlation= np.array(single_correlation).flatten().tolist()\n",
    "        single_entropy= np.array(single_entropy).flatten().tolist()\n",
    "        export_csv(\n",
    "                distance,\n",
    "                angle,\n",
    "                single_dissimilarity,\n",
    "                single_homogeneity,\n",
    "                single_contrast,\n",
    "                single_ASM,\n",
    "                single_energy,\n",
    "                single_correlation,\n",
    "                single_entropy\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoning feature section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code isn't kinda clean, it'll be run twice for 2 kinds of zoning from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning_dissimilarity=[]\n",
    "zoning_homogeneity=[]\n",
    "zoning_entropy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning_size = (4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoning(image, size):\n",
    "    sub_images = []\n",
    "    image_shape = image.shape\n",
    "    image_range = int(image_shape[0]/zoning_size[0])\n",
    "    for i in range(0, image_shape[0], image_range):\n",
    "        for j in range (0, image_shape[1], image_range):\n",
    "            sub_images.append(image[i:i+image_range, j:j+image_range])\n",
    "    return sub_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoning_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    zoning_images.append(zoning(image, zoning_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zoned_image in zoning_images:\n",
    "    for img in zoned_image:\n",
    "#         matrix_cooc = greycomatrix(img, distances=[1, 2, 3, 4, 5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256,\n",
    "#                             symmetric=True, normed=False)\n",
    "        matrix_cooc = greycomatrix(img, distances=[1], angles=[0], levels=256,\n",
    "                            symmetric=True, normed=False)\n",
    "        zoning_dissimilarity.append(greycoprops(matrix_cooc, 'dissimilarity'))\n",
    "        zoning_homogeneity.append(greycoprops(matrix_cooc, 'homogeneity'))\n",
    "        img_entropy = np.zeros((1, 1))\n",
    "        for distance in range (0, 1):\n",
    "            for angle in range(0, 1):\n",
    "                img_entropy[distance][angle] = shannon_entropy(matrix_cooc[distance][angle])\n",
    "        zoning_entropy = np.append(zoning_entropy, img_entropy)\n",
    "reshaped_zoning_entropy = np.reshape(zoning_entropy,(len(images) * zoning_size[0]**2, 1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_start = 0;\n",
    "index_jump = zoning_size[0]**2;\n",
    "img_counter = 1;\n",
    "datasets = []\n",
    "\n",
    "for distance in range (0, 1):\n",
    "    for angle in range(0, 1):\n",
    "        while img_counter<=len(images):\n",
    "            all_zoning_dissimilarity = []\n",
    "            all_zoning_homogeneity = []\n",
    "            all_zoning_entropy = []\n",
    "            for sub_zoning in range (index_start, index_start+index_jump):\n",
    "                all_zoning_dissimilarity.append(zoning_dissimilarity[sub_zoning][distance][angle])\n",
    "                all_zoning_homogeneity.append(zoning_homogeneity[sub_zoning][distance][angle])\n",
    "                all_zoning_entropy.append(reshaped_zoning_entropy[sub_zoning][distance][angle])\n",
    "\n",
    "\n",
    "            all_zoning_dissimilarity = np.array(all_zoning_dissimilarity).flatten()\n",
    "            all_zoning_homogeneity = np.array(all_zoning_homogeneity).flatten()\n",
    "            all_zoning_entropy = np.array(all_zoning_entropy).flatten()\n",
    "            \n",
    "            datasets.append(np.concatenate((all_zoning_dissimilarity, all_zoning_homogeneity, all_zoning_entropy), axis=None))\n",
    "            #keys based on range of column,  in case 2x2 zoning use 2*2*2, or 4x4 use 4*4*2 \n",
    "            keys = range(2*zoning_size[0]**2)\n",
    "            cols = []\n",
    "            for sub_img in range (1, 1+zoning_size[0]**2):\n",
    "                cols.append(\"8x8_Dissimilarity_\"+str(sub_img))\n",
    "            for sub_img in range (1, 1+zoning_size[0]**2):\n",
    "                cols.append(\"8x8_Homogeneity_\"+str(sub_img))\n",
    "            for sub_img in range (1, 1+zoning_size[0]**2):\n",
    "                cols.append(\"8x8_Entropy_\"+str(sub_img))\n",
    "                \n",
    "            index_start += index_jump;\n",
    "            img_counter +=1\n",
    "        #reshape to -1, columnsize. in case 2x2 zoning use 2*2*2, or 4x4 use 4*4*2 \n",
    "        datasets = np.array(datasets).reshape(-1, 3*zoning_size[0]**2)\n",
    "        file_name = 'glcm_'+str(distance)+'_'+str(angle)+'_zoning size='+str(zoning_size[0])+'.csv'\n",
    "        df = pd.DataFrame(datasets, columns = cols)\n",
    "        df.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
